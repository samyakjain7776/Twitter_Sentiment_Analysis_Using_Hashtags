{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XnIpJnkHuT-D"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "import keras\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1609279663355,
     "user": {
      "displayName": "Rohith Teja",
      "photoUrl": "",
      "userId": "17526535861407839040"
     },
     "user_tz": -60
    },
    "id": "VijxsP322W3W",
    "outputId": "2282a6cc-5ea8-430a-9b76-7c5075007a42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>['id', 'have', 'responded', 'if', 'i', 'were',...</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>['soon', 'sad', 'i', 'will', 'miss', 'you', 'h...</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>['my', 'boss', 'is', 'bullying', 'me']</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>['what', 'interview', 'leave', 'me', 'alone']</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>['sons', 'of', 'why', 'couldnt', 'they', 'put'...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>['wish', 'we', 'could', 'come', 'see', 'u', 'o...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>['ive', 'wondered', 'about', 'rake', 'to', 'th...</td>\n",
       "      <td>dont force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>['yay', 'good', 'for', 'both', 'of', 'you', 'e...</td>\n",
       "      <td>yay good for both of you</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>['but', 'it', 'was', 'worth', 'it']</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>['all', 'this', 'flirting', 'going', 'on', 'th...</td>\n",
       "      <td>all this flirting going on the atg smiles yay ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1  ['id', 'have', 'responded', 'if', 'i', 'were',...   \n",
       "1      549e992a42  ['soon', 'sad', 'i', 'will', 'miss', 'you', 'h...   \n",
       "2      088c60f138             ['my', 'boss', 'is', 'bullying', 'me']   \n",
       "3      9642c003ef      ['what', 'interview', 'leave', 'me', 'alone']   \n",
       "4      358bd9e861  ['sons', 'of', 'why', 'couldnt', 'they', 'put'...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0  ['wish', 'we', 'could', 'come', 'see', 'u', 'o...   \n",
       "27477  4f4c4fc327  ['ive', 'wondered', 'about', 'rake', 'to', 'th...   \n",
       "27478  f67aae2310  ['yay', 'good', 'for', 'both', 'of', 'you', 'e...   \n",
       "27479  ed167662a5                ['but', 'it', 'was', 'worth', 'it']   \n",
       "27480  6f7127d9d7  ['all', 'this', 'flirting', 'going', 'on', 'th...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                      id have responded if i were going   neutral  \n",
       "1                                               sooo sad  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                               sons of   negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                         dont force  negative  \n",
       "27478                           yay good for both of you  positive  \n",
       "27479                               but it was worth it   positive  \n",
       "27480  all this flirting going on the atg smiles yay ...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/preprocessed_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wxc2J9Gr2bQ-"
   },
   "outputs": [],
   "source": [
    "# for case 2 run this code (case 2 = selected text)\n",
    "case = \"case2-cnn\"\n",
    "\n",
    "#read data\n",
    "df = pd.read_csv(\"data/preprocessed_train.csv\")\n",
    "df.text = df.selected_text.map(lambda x:str(x))\n",
    "df.sentiment = df.sentiment.astype(\"category\")\n",
    "df.sentiment = df.sentiment.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Kiv4fMpy2wVQ"
   },
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "x_train, xtest, y_train, ytest = train_test_split(df.text.values, df.sentiment.values,stratify=df.sentiment.values, test_size=0.3,random_state=1)\n",
    "y_train = to_categorical(y_train)\n",
    "x_val = xtest[0:4122]\n",
    "y_val = to_categorical(ytest[0:4122])\n",
    "x_test = xtest[4122:]\n",
    "y_test = ytest[4122:]\n",
    "\n",
    "\n",
    "#tokenizing and padding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df.text.values)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_val = tokenizer.texts_to_sequences(x_val)\n",
    "X_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Z4oLKEuduUTR"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras import layers\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DD3YOLNLfVq5"
   },
   "outputs": [],
   "source": [
    "#activation = [\"selu\", \"elu\", \"sigmoid\", \"tanh\"]\n",
    "#optimizer = [\"adam\", \"SGD\", \"RMSprop\", \"Adadelta\"]\n",
    "#epochs = [5,10,15,20]\n",
    "#batchsize = [8,16,32,64,128]\n",
    "activation = [\"elu\"]\n",
    "optimizer = ['RMSprop']\n",
    "epochs = [5]\n",
    "batchsize = [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "nH3le1L0ApgP"
   },
   "outputs": [],
   "source": [
    "#using keras embedding\n",
    "\n",
    "def cnn_keras(activation,optimizer,epochs,batchsize):\n",
    "  embedding_dim = 100\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                          output_dim=embedding_dim,\n",
    "                          input_length=maxlen))\n",
    "\n",
    "  model.add(Conv1D(32, kernel_size=2, activation=activation))\n",
    "  model.add(layers.MaxPooling1D(2))\n",
    "  model.add(Conv1D(32, kernel_size=2, activation=activation))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv1D(16, kernel_size=2, activation=activation))\n",
    "  model.add(layers.MaxPooling1D(2))\n",
    "  model.add(Conv1D(16, kernel_size=2, activation=activation))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(64, activation='tanh'))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(Dense(3, activation='softmax'))\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=batchsize)\n",
    "  \n",
    "  return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3134292,
     "status": "ok",
     "timestamp": 1609199348299,
     "user": {
      "displayName": "Rohith Teja",
      "photoUrl": "https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg",
      "userId": "01155222072916958278"
     },
     "user_tz": -60
    },
    "id": "9F36uecY_L9k",
    "outputId": "b93dbad5-400a-4ab0-b6d8-03e7cdb4b4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy score =  0.8391947610962891\n",
      "test f1 score =  0.8394404075174307\n",
      "time taken is  99.58482360839844\n"
     ]
    }
   ],
   "source": [
    "# Experimenting using Keras Embeddings\n",
    "\n",
    "sel_activation_final = 'elu'\n",
    "sel_optimizer_final = 'RMSprop'\n",
    "sel_epoch_final = 5\n",
    "sel_batch_final = 8\n",
    "\n",
    "# Training the Model\n",
    "t0 = time()\n",
    "history, model = cnn_keras(sel_activation_final,sel_optimizer_final,sel_epoch_final,sel_batch_final)\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "print(\"test accuracy score = \",accuracy_score(y_pred=pred, y_true=y_test))\n",
    "print(\"test f1 score = \",f1_score(y_pred=pred, y_true=y_test, average=\"weighted\"))\n",
    "\n",
    "t1 = time()\n",
    "print(\"time taken is \", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "inp = [\"this is a happy tweet\", \"sad tweet\"]\n",
    "X_test1 = tokenizer.texts_to_sequences(inp)\n",
    "X_test1 = pad_sequences(X_test1, padding='post', maxlen = maxlen)\n",
    "print(np.argmax(model.predict(X_test1), axis = -1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2. CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
